#+begin_export html
---
layout: post
title: Números de punto flotante
date: 2019-03-10
author: nsm
email: nsm.aprox@gmail.com
---
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
#+end_export

En [[https://aprox.github.io/posts/representacion-de-enteros][otro post]] vimos algunas formas usadas para representar números
enteros en las computadoras.  Pero muchas veces necesitamos
representar número /reales/, no sólo enteros. Es decir, si tenemos por
ejemplo una lista y queremos saber cuantos elementos contiene, o si
queremos ver el tercero o el cuarto, o cualquier posición en
particular, entonces podemos usar números naturales (incluyendo el
cero) o, como se suele decir, enteros sin signo. Sin embargo, existen
aplicaciones en las cuales no es suficiente con los enteros.

Esto no significa que si el resultado de una cuenta no es entero
tengamos que usar necesariamente una representación diferente. Por
ejemplo, si un grupo de amigos tiene que dividir los gastos de una
comida y entonces alguien con una calculadora divide el total por la
cantidad que sean, si bien muy probablemente el resultado no sea
entero, probablemente tampoco sea necesaria esa precisión en este
caso. Por otro parte, incluso si fuera necesario conocer con la mayor
exactitud posible, no hay monedas para cantidades inferiores a un
centavo. Entonces, expresando las cantidades en centavos el resultado
obtendrá suficiente precisión.

Es más, incluso cuando necesitamos hacer cuentas con números reales,
los resultados obtenidos en la computadora son aproximaciones, no son
exactos, si bien la aproximación puede ser suficientemente cercana
para que no resulte un problema, en forma análoga al ejemplo
mencionado.

Pero para los números reales se usa la representación de /punto
flotante/. Esta representación es igual a la notación
científica. Veamos algunos ejemplos decimales.

Supongamos que, de modo similar a como ocurre con las computadoras,
tenemos un cantidad fija de 5 dígitos para representar un número, y
queremos representar el número correspondiente a la población mundial
que en 2017 [[https://es.wikipedia.org/wiki/Poblaci%C3%B3n_mundial][según wikipedia]] es de 7.350 millones, o sea
7.350.000.000. Claramente, con 5 dígitos no nos alcanza. ¿Qué podemos
hacer? Bueno, algo que podemos hacer es decir que vamos a expresar en
millones (que fue lo que hicimos en un principio). Esto no es otra
cosa que decir que la población mundial es de $7350 \times
10^6$. Tenemos entonces el número descompuesto en dos partes, cuyo
producto es el número a representar. Por otra parte, probablemente
este número sea una aproximación y no el número exacto, pero también
probablemente las primeras cifras (las más significativas) sí se
correspondan con el valor exacto. Ahora bien, si fuéramos a usar esta
representación en la computadora, con el exponente fijo (por ejemplo
$10^6$), podríamos usarla para estas magnitudes (población mundial),
pero no nos serviría para muchas otras, como por ejemplo la división
de los gastos del ejemplo de más arriba.

Por ese motivo, es necesario poder decir que el número está expresado
en millones, o en decenas, o en unidades de mil, o en decimales,
etc. De este modo, el número se representa de la siguiente manera:

 \[ f = (-1)^s \times d_1d_2...d_t \times \beta^\epsilon \]

donde $s$ es el *signo* (0 o 1), los $d_i$ ($i = 1, .., t$) son
dígitos enteros que componen la *mantisa* y cumplen $0\leq d_i <
\beta$. $\beta$ es la base (10 en los ejemplos de arriba, en la
computadora suele ser 2). $\epsilon$ es el exponente (al que se eleva
la base). $t$ es la cantidad de dígitos $d_i$ presentes en la mantisa
y se llama *precisión*.

Es quizá un poco extraño el modo en que expresamos el signo. Después
de todo, si sólo puede ser $1$ o $-1$ podría haber dicho que $s$ valía
eso y que multiplicaba el resto del número. Usé esta otra forma,
que creo que es la habitual, y supongo que porque en realidad el signo
es un bit, y un bit es como si fuera un dígito binario.

Ahora tomemos el número 8000 como ejemplo.  $8000_{10} = 1\ 1111\
 0100\ 0000_2$ y necesitamos 13 bits para representarlo. Como la
 representación es binaria, el número que multiplica la mantisa no es
 una potencia de 10 sino de 2. Por ejemplo $8000 = 125 \times 2^6$ ya
 que $125_{10} = 111\ 1101_2$. Como siempre, podemos representar el
 mismo número con distintas opciones de exponente y mantisa. Por ese
 motivo, conviene adoptar la convención siguiente. Dado que el número
 esta representado con dígitos binarios (cero o uno), entonces con la
 única excepción del cero, todo número tendrá algún uno en su
 representación. De este modo, podemos asumir que, cuando no se trata
 del cero, hay un uno que es el más significativo, es decir, el que
 está más a la izquierda en la forma habitual de escribir los
 números. Entonces, el número está normalizado si ese uno es el único
 "a la izquierda de la coma", es decir, el valor del exponente es
 tal que el número que queremos expresar es $1,d_2d_3... \times
 2^\epsilon$ ($e$ vendría a ser cualquier exponente).

De esta forma, ya no hay dos representaciones distintas para un mismo
número, porque asumimos que están normalizados.


Por último, una cosa que se puede hacer es obviar ese uno más
significativo, es decir, asumir que para cualquier número representado
ese uno está implícito y no usar un bit en él. Esto no genera
inconvenientes y da un bit más que se puede aprovechar para agregar un
dígito. Supongo que una forma conveniente de distinguir el cero en
este caso es fijarse en el exponente y si es cero se trata del cero y
no del uno. Pues ¿para qué querríamos que el exponente pueda valer
cero si ya podemos representar el uno de otra forma?
